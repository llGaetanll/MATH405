\documentclass[12pt]{article}
\usepackage{amssymb}
\usepackage{amsmath, amsthm}
\usepackage{xcolor}
\usepackage[
    top=10mm,
    bottom=10mm,
    left=30mm,
    right=30mm,
    marginparwidth=0mm,
    marginparsep=0mm,
    % headheight=15pt,
    centering,
    % showframe,
    % includefoot,
    % includehead
]{geometry}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{framed}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{chngcntr}
\usepackage{float}
\usepackage{multicol}


% \input xypic (for commutative diagrams)
% \include{mssymb}

\def\A{{\mathbb A}}
\def\P{{\mathbb P}}
\def\N{{\mathbb N}}
\def\Z{{\mathbb Z}}
\def\Q{{\mathbb Q}}
\def\R{{\mathbb R}}
\def\C{{\mathbb C}}
\def\F{{\mathbb F}}
\def\O{{\cal O}}
\let\sec\S
\let\S\relax
\def\S{{\mathfrak S}}
\def\g{{\mathfrak g}}
\def\p{{\mathfrak p}}
\def\h{{\mathfrak h}}
\def\n{{\mathfrak n}}
\def\v{{\mathfrak v}}
\def\m{{\mathfrak m}}
\def\a{{\alpha}}


\newcommand{\skipline}{\vspace{\baselineskip}}
\newcommand{\dis}{\displaystyle}
\newcommand{\noin}{\noindent}


% remove all paragraph indents
\setlength{\parindent}{0pt}

% Figure counter include section
\counterwithin{figure}{section}

% Cleaner figures
\newcommand{\fig}[3][0.4]{
  \begin{figure}[H]
    \centering
    \includegraphics[width=#1\textwidth, keepaspectratio]{#2}
    \caption{#3}
  \end{figure}
}
% Mathematical notation


\newcommand{\Span}{\mathrm{Span}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\nullity}{\mathrm{nullity}}
\newcommand{\longhookrightarrow}{\lhook\joinrel\relbar\joinrel\rightarrow}
\newcommand{\la}{\leftarrow}
\newcommand{\ra}{\rightarrow}
\newcommand{\La}{\Leftarrow}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\dbar}{\overline{\partial}}
\newcommand{\gequ}{\geqslant}
\newcommand{\lequ}{\leqslant}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\End}{\mathrm{End}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Coker}{\mathrm{Coker}}
\newcommand{\Row}{\mathrm{Row}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\Id}{\mathrm{Id}}
% \newcommand{\mod}{\mathrm{mod }}
\newcommand{\un}{\underline}
\newcommand{\ov}{\overline}
\newcommand{\wt}{\widetilde}
\newcommand{\wh}{\widehat}
\newcommand{\pr}{\prime}
\newcommand{\rk}{\mathrm{rk}}
\newcommand{\im}{\mathrm{Im}}

% Linear Algebra

\newcommand{\lind}{linearly independent}
\newcommand{\ldep}{linearly dependent}
\renewcommand{\vec}[1]{
  {\bf #1}
}
\newcommand{\lincomb}[3]{
  #1_{1}#2_{1} + #1_{2}#2_{2} + \cdots + #1_{#3}#2_{#3}
}
\newcommand{\neglincomb}[3]{
  -#1_{1}#2_{1} - #1_{2}#2_{2} - \cdots - #1_{#3}#2_{#3}
}
\newcommand{\constants}[2]{
  #1_{1}, #1_{2}, \cdots, #1_{#2}
}
\newcommand{\constantsz}[2]{
  #1_{0}, \constants{#1}{#2}
}

% Analysis
\newcommand{\limfty}[1]{\lim_{#1 \to \infty}}
\newcommand{\seq}[2]{\{#1_{#2}\}_{#2 \in \N}}
\newcommand{\sseq}[3]{\{#1_{#2_{#3}}\}_{#3 \in \N}}
\newcommand{\chep}{Let $\epsilon > 0$}

% Category Theory
\newcommand{\catC}{\mathcal{C}}
\newcommand{\catD}{\mathcal{D}}
\newcommand{\functF}{\mathcal{F}}
\newcommand{\functG}{\mathcal{G}}
\newcommand{\functI}{\mathcal{I}}
\newcommand{\functU}{\mathcal{U}}

\newcommand{\op}[1]{#1^{\mathrm{op}}}
\newcommand{\Obj}{\mathrm{Obj}}

\newcommand{\Set}{\mathbf{Set}}
\newcommand{\Grp}{\mathbf{Grp}}
\newcommand{\Top}{\mathbf{Top}}
\newcommand{\cRing}{\mathbf{cRing}}
\newcommand{\BanAnaMan}{\mathbf{BanAnaMan}}
\newcommand{\FinSet}{\mathbf{FinSet}}
\newcommand{\Vect}{\mathbf{Vect}}
\newcommand{\Two}{\mathbf{2}}


% ================= %
% Headers & Footers
% ================= %
\pagestyle{fancy}
\fancyhf{}
\newcommand{\intros}[3]{
  \lhead{\textbf{#1} {#2}}
  \rhead{#3}}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0pt}



% ================= %
%       Utils
% ================= %
\newcommand{\induction}[3]{
  \textbf{Base Case} #1 \\
  \textbf{Inductive Hypothesis} \\ #2 \\
  \textbf{Inductive Step} \\ #3
}



% Used to list all problems on homework
\newcommand{\problems}[1]{
  \medskip \noin
  {\bf Problems}

  #1

  \medskip{}
}


% augmented matrices
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

% ================= %
%      Box Meta
% ================= %

% #2 - FG Color
% #3 - BG Color
\newenvironment{fancyleftbar}[3][\hsize]
{%
    \def\FrameCommand
    {%
        {\color{#2}\vrule width 3pt}%
        \hspace{0pt}%must no space.
        \fboxsep=\FrameSep\colorbox{#3}%
    }%
    \MakeFramed{\hsize#1\advance\hsize-\width\FrameRestore}%
}
{\endMakeFramed}

% Used to allow the color argument to pass through the environment%
\newsavebox{\boxqed} 

% #1 - Header
% #2 - FG Color
% #3 - BG Color
\newenvironment{fancybox}[3]{
  \sbox\boxqed{\textcolor{#2}{$\blacksquare$}}
  \begin{fancyleftbar}{#2}{#3}

  \noin
  {\large \sc #1} \\
}
{

  \medskip
  \noin
  \usebox\boxqed

  \end{fancyleftbar}
}

% #1 - Text header
% #2 - Outer Text
% #3 - Inner Text
% #4 - Inner Header
% #5 - FG Color
% #6 - Background Color
\newcommand{\boxmeta}[6]{
  \bigskip \bigskip \noin
  {\large\sc #1}

  \smallskip\noin
  #2

  \begin{fancybox}{#4}{#5}{#6}
    \noin
    #3
  \end{fancybox}
}

% #1 - Title
% #2 - FG Color
% #3 - BG Color
% #4 - Inner Text
\newcommand{\baronly}[4]{
  \begin{fancyleftbar}{#2}{#3}{\large \sc #1}

    #4
  \end{fancyleftbar}
}

% ================= %
%     Box Colors
% ================= %

\definecolor{theorem_fg}{HTML}{EABAC3}
\definecolor{theorem_bg}{HTML}{F9EEF0}

\definecolor{problem_fg}{HTML}{ABABAB}
\definecolor{problem_bg}{HTML}{EDEDED}

\definecolor{lemma_fg}{HTML}{D0C97D}
\definecolor{lemma_bg}{HTML}{FCF9DB}

\definecolor{prop_fg}{HTML}{7DDB89}
\definecolor{prop_bg}{HTML}{D7FADB}

\definecolor{defn_fg}{HTML}{83D4CF}
\definecolor{defn_bg}{HTML}{E7FCFB}

% ================= %
%     Box Meso
% ================= %

\newcommand{\thm}[2]{
  \boxmeta{Theorem}{#1}{#2}{Proof}{theorem_fg}{theorem_bg}
}

\newcommand{\namedtheorem}[3]{
  \boxmeta{#1}{#2}{#3}{Proof}{theorem_fg}{theorem_bg}
}

\newcommand{\prob}[3]{
  \boxmeta{Problem #1}{#2}{#3}{Solution}{problem_fg}{problem_bg}
}

\newcommand{\exampleprob}[2]{
  \boxmeta{Example}{#1}{#2}{Solution}{problem_fg}{problem_bg}
}

\newcommand{\lemma}[2]{
  \boxmeta{Lemma}{#1}{#2}{Proof}{lemma_fg}{lemma_bg}
}

\newcommand{\namedlemma}[3]{
  \boxmeta{#1}{#2}{#3}{Proof}{lemma_fg}{lemma_bg}
}

\newcommand{\corr}[2]{
  \boxmeta{Corrolary}{#1}{#2}{Proof}{lemma_fg}{lemma_bg}
}

\newcommand{\proposition}[2]{
  \boxmeta{Proposition}{#1}{#2}{Proof}{prop_fg}{prop_bg}
}

\newcommand{\definition}[1]{
  \baronly{Definition}{defn_fg}{defn_bg}{#1}
}

\newcommand{\example}[1]{
  \baronly{Example}{problem_fg}{problem_bg}{#1}
}

\newcommand{\remark}[1]{
  \baronly{Remark}{problem_fg}{problem_bg}{#1}
}

\def\B{\mathcal B}
\def\P{\mathcal P}

\newcommand{\btw}[1]{
    $\langle$ #1 $\rangle$
}

\renewcommand{\date}[1]{\underline{\bf #1}}

\def\eps{\varepsilon}


% create a command for TODOs
\newcommand{\TODO}{\color{red}\textbf{TODO}\color{black}}



\begin{document}
  \footnotesize
  % \begin{multicols*}{2}

    \date{Fri. Feb 10 2023}

    \section{Vector Spaces}

    Suppose that $V$ is a finite dimensional vector space over $F$, with $\dim(V)
    = n$.

    $V$ may have {\it many different} bases, we know that they all have the same
    size $n$.

    Say $\B = \{\alpha_1, ..., \alpha_n\}$ is a basis fix the ordering of $\B$.

    Fix the ordering of $\B$.

    \thm {
      For any $\alpha \in V$, there is a unique $n$ tuple $(x_1, ..., x_n) \in F^n$
      such that

      \[
        \alpha = x_1 \alpha_1 + \cdots + x_n \alpha_n
      \]
    }
    {
      Existence is immediate, since $\B$ is a basis, thus $\B$ spans $V$.

      {\bf Uniqueness}

      Say $\alpha = x_1 \alpha_1 + \cdots + x_n \alpha_n$
      and $\alpha = y_1 \alpha_1 + \cdots + y_n \alpha_n$.

      Then we have that

      $x_1 \alpha_1 + \cdots + x_n \alpha_n - y_1 \alpha_1 + \cdots + y_n \alpha_n
      = 0$, so $(x_1 - y_1)\alpha_1 + \cdots + (x_n - y_n)\alpha_n = 0$

      But since $\{\alpha_1, ..., \alpha_n\}$ is linearly independent, all
      coefficients must be $0$.
    }

    What this means is that, for a vector space $V$, there is an associated
    mapping in $F^n$. Notice that we know nothing about the vectors $\alpha_i$.

    We define $[\alpha]_{\B}$ to be the {\it coordinates} of $\alpha$ with
    respect to $\B$.

    {\bf Check}: The mapping $\alpha \mapsto [\alpha]_{\B} \in F^n$ satisfies

    \begin{enumerate}
      \item One to one-ness
      \item Onto-ness
      \item "Additive", for any $\alpha, \beta \in V$, if $\alpha = x_1 \alpha_1
        + \cdots + x_n \alpha_n$ and $\beta = y_1 \alpha_1 + \cdots + y_n
        \alpha_n$. Then

        \[
          [\alpha + \beta]_{\B} = \begin{bmatrix}
            x_1 + y_1 \\
            x_2 + y_2 \\
            \vdots \\
            x_n + y_n \\
          \end{bmatrix}
          =
          \begin{bmatrix}
            x_1 \\
            x_2 \\
            \vdots \\
            x_n \\
          \end{bmatrix}
          +
          \begin{bmatrix}
            y_1 \\
            y_2 \\
            \vdots \\
            y_n \\
          \end{bmatrix}
          =
          [\alpha]_{\B}
          +
          [\beta]_{\B}
        \]
      \item $[c\alpha]_{\B} + c[\alpha]_{\B}$
    \end{enumerate}

    There exists an {\it isomorphism} between $V$ and $F^n$.

    \example{
      Let $\P$ be the space of al polynomials. Let $f(x) = x^3$, and $g(x) =
      x^5$. Then, let

      \[
        V = \Span\{f, g\} = \{\text{all } ax^3 + bx^5 : a, b \in F\}
      \]

      then, $\dim(V) = 2$, since $f$ and $g$ are linearly independent.

      Typical $h(x) \in V$, say $h(x) = 10x^3 - 2x^5$.

      \[
        [h]_{\B} = \begin{bmatrix}
          10 \\
          -2
        \end{bmatrix}
      \]
    }

    \btw {
      $[h]_{\B}$ is the mapping of $h$ to $F^n$. \TODO{} is this right?
    }

    Now let $k(x) = 2x^3 + 4x^5$ and $l(x) = x^3 + 3x^5$. Since $k, l$ are
    linearly independent, they form another basis of $V$.

    \[
      \B' = \{k(x), l(x)\}
    \]

    \subsection{Change of Basis}

    Given $\B = \{\alpha_1, ..., \alpha_n\}$, and $\B' = \{\alpha_1', ...,
    \alpha_n'\}$ bases for $V$.

    We want to describe the map going from $[\alpha]_{\B} \mapsto
    [\alpha]_{\B'}$.

    \btw{ We want to find $\text{The $\B$ coordinate of $\alpha$} \mapsto
    \text{the $\B'$ coordinate of $\alpha$}$}

    {\bf Step 1}.

    Compute the $\B$ coordinate of $\alpha_1', ..., \alpha_n'$, {\it old}
    coordinates of the {\it new} basis elements. \\

    {\bf Step 2}.

    For an $n \times m$ matrix

    \[
      P = \Big[ [\alpha_1']_{\B}, ..., [\alpha_n']_{\B} \Big]
    \]

    {\bf Check}: for any $\alpha \in V$

    \[
      [\alpha]_{\B} = P [\alpha]_{\B'}
    \]

    {\bf Ans}: This is what we actually want

    \[
      [\alpha]_{\B'} = P^{-1} [\alpha]_{\B}
    \]

    \date{Mon. Feb 13 2023}

    \TODO{} Missing {\it some} info

    {\bf Want}: Describe the mapping $T: F^n \to F^n$

    \[
      T([\alpha]_{\B_\text{old}}) = [\alpha]_{\B'_{\text{new}}}
    \]

    \btw {
      If we switch the basis for some reason, we want to see what the new
      coordinates are.
    }

    {\bf To do this}: For each $\alpha_j'$, compute
    $[\alpha_j']_{\B_\text{old}}$. Let

    \[
      P = \Big[[\alpha_1']_{\B_\text{old}} \cdots [\alpha_n']_{\B_{\text{old}}}\Big]
    \]

    be an $n \times n$ matrix.

    {\bf Claim}: For any $\alpha \in V$

    \[
      P \cdot [\alpha]_{\B'_\text{new}} = [\alpha]_{\B_\text{old}}
    \]

    {\bf How?}

    \[
      P \cdot [\alpha_1']_{\B'_\text{new}} = P \cdot \begin{bmatrix}
        1 \\
        0 \\
        \vdots \\
        0
      \end{bmatrix}
      = [\alpha_1']_{\B_\text{old}}
    \]

    This is the $1^{st}$ column of $P$, and similarly for all columns.

    {\bf Thus}: For any $\alpha \in V$, 

    \[
      [\alpha]_\text{new} = P^{-1} \cdot [\alpha]_\text{old}
    \]

    \example {
      In practice, we have the following.

      $V = \Span(\{x^3, x^5\})$ subspace of $\P = \text{all polynomials}$. Let
      $f(x) = x^3, g(x) = x^5, \B = [x^3, x^5]$. Let $h(x) = 10^3 - 2x^5 \in V$.

      {\bf Question}: What are the coordinates of $h$ with respect to $\B$?

      {\bf Answer}:
      \[
        [h]_{\B} = \begin{bmatrix}
          10 \\
          -2
        \end{bmatrix}
      \]
    }

    \example{
      Let $k(x) = 2x^3 + 5x^5$, $l(x) = x^3 + 3x^5$.

      Let $\B' = \{k(x), l(x)\}$ be another basis of $V$.

      {\bf Question}: What are the coordinates of $h$ with respect to $\B'$?

      {\bf Answer}:

      $[k(x)]_{\B} = \begin{bmatrix} 2 \\ 5 \end{bmatrix}$ and $[l(x)]_{\B} =
      \begin{bmatrix} 1 \\ 3 \end{bmatrix}$.

      So

      \[
        P = \begin{bmatrix}
          2 & 1 \\
          5 & 3 \\
        \end{bmatrix}
      \]

      {\bf Check}:

      \[
        P^{-1} = \begin{bmatrix}
          3 & -1 \\
          -5 & 2 \\
        \end{bmatrix}
      \]

      Then

      \[
        \begin{bmatrix}
          3 & -1 \\
          -5 & 2 \\
        \end{bmatrix}
        \cdot
        \begin{bmatrix}
          10 \\ -2
        \end{bmatrix}
        =
        \begin{bmatrix}
          32 \\ -54
        \end{bmatrix}
      \]

      {\bf This means}:

      \[
        h(x) = 32k(x) - 54l(x) = 10x^3 - 2x^5
      \]

      Which is what we expect.

    }

    \example {
      Let $V = \R^2$. Standard basis $\B = \{\eps_1, \eps_2\} = \{(1, 0), (0, 1)\}$

      \[
        [(5, 4)]_{\B} = \begin{bmatrix}
          5 \\ 4
        \end{bmatrix}
      \]

      Fix angle $\theta$, Let

      \[
        \B' = \{(\cos(\theta), \sin(\theta)), (-\sin(\theta), \cos(\theta))\}
      \]

      {\bf Question}: What is $\begin{bmatrix} 5 \\ 4
      \end{bmatrix}_{\B'_\text{new}}$?

      {\bf Answer}:

      \begin{enumerate}
        \item Form $P$

          \[
            [(\cos(\theta), \sin(\theta))]_{\B} = \begin{bmatrix} \cos(\theta)
            \\ \sin(\theta) \end{bmatrix}
          \]

          \[
            [(-\sin(\theta), \cos(\theta))]_{\B} = \begin{bmatrix} -\sin(\theta)
            \\ \cos(\theta) \end{bmatrix}
          \]

          Then 

          \[
            P = \begin{bmatrix}
              \cos(\theta) & -\sin(\theta) \\
              \sin(\theta) & \cos(\theta)
            \end{bmatrix}
          \]

          {\bf Fact}:

          \[
            P^{-1} = \begin{bmatrix}
              \cos(\theta) & \sin(\theta) \\
              -\sin(\theta) & \cos(\theta)
            \end{bmatrix}
          \]

          so we have

          \begin{align*}
            [(5, 4)]_{\B'_\text{new}} =&P^{-1}
            \begin{bmatrix} 5 \\ 4 \end{bmatrix} \\
            =&\begin{bmatrix}
              \cos(\theta) & \sin(\theta) \\
              -\sin(\theta) & \cos(\theta)
            \end{bmatrix}
            \begin{bmatrix} 5 \\ 4 \end{bmatrix} \\
            =&\begin{bmatrix}
              5\cos(\theta) & 4\sin(\theta) \\
              -5\sin(\theta) & 4\cos(\theta)
            \end{bmatrix}
          \end{align*}
      \end{enumerate}
    }

    \section{Chapter 3}

    Say $V$, $W$ are both vector spaces over the same field $F$.
    
    \definition{
      A {\bf Linear Transformation} $T: V \to W$ is a function satisifying two
      rules

      \begin{enumerate}
        \item For all $\alpha, \beta \in V$,

          \[
            T(\alpha + \beta) = T(\alpha) + T(\beta)
          \]

          Note that the first $+$ is addition in $V$, but the second
          is addition in $W$.

        \item For all $\alpha \in V$ and $c \in F$,

          \[
            T(c\alpha) = cT(\alpha)
          \]
      \end{enumerate}

      \btw{The book combines these two into one.}
    }

    Lots of examples to come

    {\bf Two basic facts}:

    Suppose that $T: V \to W$ is a linear transformation
    \begin{enumerate}
      \item $T(0) = 0$

        {\bf Proof}:

        $T(0 + 0) = T(0) + T(0)$ thus $T(0) = 0$.

        \btw{Always be aware of where the $0$ lives}

        \TODO{} Not super clear

      \item For all $\{\alpha_1, ..., \alpha_n\} \subseteq V$, all $\{c_1, ...,
        c_n\} \in F$,

        \[
          c_1 T(\alpha_1) + \cdots + c_n T(\alpha_n)
        \]

        {\bf Proof} Easy induction on $n$.
    \end{enumerate}

    \example {
      Take $A \in F^{m \times n}$ an $m \times n$ matrix with entries in $F$.

      Then $T_A: F^n \to F^m$ given by $T_A(x) = A \cdot X$ is a linear
      transformation.

      {\bf Check}

      Chose any $X, Y \in F^n$, then

      \[
        T_A(X + Y) = A \cdot (X + Y) = A \cdot X + A \cdot Y = T_A(X) + T_A(Y)
      \]

      For $c \in F$, have

      \[
        T_A(cX) = A \cdot (cX) = cAX = c T_A(X)
      \]

      which is what we expect.
    }

    \example {
      Consider $\P$ the set of all polynomials $a_0 + a_1x + \cdots + a_n x^n$.

      Differentiation

      \[
        D: \P \to \P
      \]

      $F(f) = f'$, the {\bf derivative}

      {\bf Claim}: $D: \P \to \P$ is a linear transformation.

      {\bf Check}: 
      \[
        D(f + g) = (f + g)' = f' + g' = D(f) + D(g)
      \]

      and for $c \in F$,

      \[
        D(cf) = (cf)' = c \cdot f' = c \cdot D(f)
      \]

      which is what we expect.
    }

    \example {
      Let $C(\R)$ be all combinations of all functions $f: \R \to \R$.

      Define $I: C(\R) \to C(\R)$ the {\bf integral}

      \[
        I(f) = \int_0^x f(t)dt
      \]

      \btw {
        Note that the integral exists because you can always integrate a
        contiunous function.
      }

      The result is also continuous and differentiable by the Fundamental
      Theorem of Calculus.

      \[
        D(I(f)) = f
      \]

      Is the {\bf Fundamental Theorem of Calculus}.

      Therefore $I(f)$ really {\it is} continuous, $I(f) \in C(\R)$.

      {\bf Question}: Is it really linear?

      {\bf Check}:

      \begin{align*}
        I(f + g) =&\int_0^x (f(t) + g(t))dt \\
                 =&\int_0^x f(t)dt + \int_0^x g(t)dt \\
                 =&I(f) + I(g)
      \end{align*}

      and

      \[
        I(cf) = \int_0^x cf(t)dt = c\int_0^x f(t)dt = cI(f)
      \]
    }

  % \end{multicols*}
\end{document}
